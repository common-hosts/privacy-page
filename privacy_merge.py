from __future__ import annotations

import html
import sys
import urllib
import subprocess
import os

import requests
import time
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
from selenium.webdriver.support.wait import WebDriverWait

import base64
import gzip
import json
import re
from io import BytesIO
from pathlib import Path
from DrissionPage import Chromium

# è¿™é‡Œçš„ URL å’Œè¡¨æ ¼ ID è¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
# è¡¨æ ¼ URL ç¤ºä¾‹: https://superxgr.larksuite.com/base/SebGbrq2yaNXXSsVOcJudpzxsCf?table=tblTywpT1yCgOaV7&view=vewOnkM00z
# API æ¥å£ç¤ºä¾‹: SebGbrq2yaNXXSsVOcJudpzxsCf/records
PRIVACY_GEN_URL = "https://app-privacy-policy-generator.firebaseapp.com/"
table_url = "https://superxgr.larksuite.com/base/SebGbrq2yaNXXSsVOcJudpzxsCf?table=tblTywpT1yCgOaV7&view=vewOnkM00z"
api_keyword = "SebGbrq2yaNXXSsVOcJudpzxsCf/records"
browser = None
browser_port = 9527
cookies_str = ""
app_name: str = ""
company_name: str = ""
email: str = ""

# ç”¨äº finally å®‰å…¨é€€å‡º
driver = None

# ç”Ÿæˆå¹¶å‘å¸ƒé™æ€é¡µéœ€è¦çš„è¾“å‡ºæ–‡ä»¶
PRIVACY_TEXT_OUT = Path(__file__).resolve().parent / "privacy_text.txt"
TEMPLATE_HTML_PATH = Path(__file__).resolve().parent / "muban.html"


def html_to_formatted_text(html_fragment: str) -> str:
    """å°† privacy_simple_content çš„ innerHTML è½¬æˆè¾ƒå¥½ç²˜è´´çš„çº¯æ–‡æœ¬ï¼Œä¿ç•™æ®µè½ã€åˆ—è¡¨å’Œé“¾æ¥ç»“æ„ã€‚"""
    if not html_fragment:
        return ""
    soup = BeautifulSoup(html_fragment, "html.parser")

    lines = []

    from bs4.element import NavigableString, Tag

    def handle_node(node, indent_level=0):
        indent = "  " * indent_level

        if isinstance(node, NavigableString):
            text = str(node)
            text = text.replace("\u200b", "").strip("\n")
            if text:
                lines.append(indent + text)
            return

        if not isinstance(node, Tag):
            return

        name = (node.name or "").lower()

        if name == "br":
            lines.append("")
            return

        if name in {"p", "div", "section", "strong", "b", "em", "i", "h1", "h2", "h3", "h4", "h5", "h6"}:
            before = len(lines)
            for child in node.children:
                handle_node(child, indent_level)
            after = len(lines)
            if after > before and (not lines or lines[-1] != ""):
                lines.append("")
            return

        if name in {"ul", "ol"}:
            if lines and lines[-1] != "":
                lines.append("")
            idx = 1
            for li in node.find_all("li", recursive=False):
                prefix = "- " if name == "ul" else f"{idx}. "
                buf = []

                def collect(child):
                    if isinstance(child, NavigableString):
                        t = str(child).replace("\u200b", "").strip("\n")
                        if t:
                            buf.append(t)
                    elif isinstance(child, Tag):
                        cname = (child.name or "").lower()
                        if cname == "br":
                            buf.append(" ")
                        elif cname == "a":
                            href = child.get("href") or ""
                            visible = child.get_text(strip=True)
                            if href and visible:
                                buf.append(f"{visible} ({href})")
                            else:
                                buf.append(visible or href)
                        else:
                            for g in child.children:
                                collect(g)

                for c in li.children:
                    collect(c)
                li_text = "".join(buf)
                li_text = re.sub(r"\s+", " ", li_text).strip()
                if li_text:
                    lines.append(indent + prefix + li_text)
                for sub in li.find_all(["ul", "ol"], recursive=False):
                    handle_node(sub, indent_level + 1)
                if lines and lines[-1] != "":
                    lines.append("")
                idx += 1
            return

        if name == "a":
            href = node.get("href") or ""
            visible = node.get_text(strip=True)
            if href and visible:
                lines.append(indent + f"{visible} ({href})")
            else:
                lines.append(indent + (visible or href))
            return

        for child in node.children:
            handle_node(child, indent_level)

    root = soup.find(id="privacy_simple_content") or soup
    for c in root.children:
        handle_node(c, 0)

    out = []
    blank = 0
    for ln in lines:
        if ln.strip() == "":
            blank += 1
            if blank <= 2:
                out.append("")
        else:
            blank = 0
            out.append(ln)

    text = "\n".join(out)
    text = text.replace("\r\n", "\n")
    text = re.sub(r"\n{3,}", "\n\n", text).strip()
    return text


def copy_to_clipboard_macos(text: str) -> bool:
    """åœ¨ macOS ä½¿ç”¨ pbcopy å¤åˆ¶æ–‡æœ¬åˆ°ç³»ç»Ÿå‰ªè´´æ¿ã€‚"""
    if not text:
        return False
    try:
        subprocess.run(["pbcopy"], input=text.encode("utf-8"), check=True)
        print("âœ… å·²å¤åˆ¶åˆ°ç³»ç»Ÿå‰ªè´´æ¿ (pbcopy)")
        return True
    except Exception as e:
        print(f"âš ï¸ å¤åˆ¶åˆ°å‰ªè´´æ¿å¤±è´¥: {e}")
        return False


def get_gzip_json_from_api(timeout: int = 60):
    """
    1. ç›‘å¬æ¥å£æ•è·åŠ¨æ€å‚æ•°ã€‚
    2. æ‰‹åŠ¨æ‰«ç ç™»å½•ï¼Œåˆ·æ–°é¡µé¢è§¦å‘æ¥å£ã€‚
    3. ä¿®æ”¹æ•è·åˆ°çš„ URLï¼Œè®¾ç½® offset=0ã€‚
    4. æå– Cookiesï¼Œä½¿ç”¨ requests åº“é‡æ–°å‘é€è¯·æ±‚ã€‚
    5. è§£æå“åº”ï¼Œè§£å‹ Gzip æ•°æ®ã€‚
    """
    global browser
    if browser is None:
        browser = Chromium(browser_port)

    tab = browser.latest_tab
    tab.get(table_url)
    print(f"ğŸ” å¼€å§‹ç›‘å¬æ¥å£: {api_keyword}")
    tab.listen.start(api_keyword)

    input("è¯·æ‰«ç ç™»å½•å¹¶æŒ‰ Enter ç»§ç»­ >>> ")
    tab.refresh()  # è§¦å‘æ¥å£è¯·æ±‚

    print(f"ğŸ” å¼€å§‹æ•è·æ¥å£è¯·æ±‚...")
    # ç­‰å¾…æ¥å£è§¦å‘
    req = tab.listen.wait(timeout=timeout)
    tab.listen.stop()  # æ•è·åˆ°ååœæ­¢ç›‘å¬

    if not req:
        print(f"âŒ {timeout} ç§’å†…æœªæ•è·åˆ°æ¥å£è¯·æ±‚ã€‚")
        return None

    # --- 1. è·å–åŸå§‹ URL å¹¶ä¿®æ”¹ offset ---
    original_url = req.url
    print(f"âœ… æ•è·åˆ°åŸå§‹æ¥å£: {original_url}")

    # è§£æ URL å’ŒæŸ¥è¯¢å‚æ•°
    parsed_url = urllib.parse.urlparse(original_url)
    query_params = urllib.parse.parse_qs(parsed_url.query)

    # ä¿®æ”¹ offset å‚æ•°ä¸º 0ï¼ˆè·å–æ‰€æœ‰æ•°æ®ï¼‰
    query_params["offset"] = ["0"]

    # é‡æ–°æ„å»ºæŸ¥è¯¢å­—ç¬¦ä¸²å’Œå®Œæ•´çš„ URL
    new_query_string = urllib.parse.urlencode(query_params, doseq=True)
    new_url = urllib.parse.urlunparse(parsed_url._replace(query=new_query_string))

    print(f"ğŸ”„ æ­£åœ¨ç”¨ä¿®æ”¹åçš„ URL (åå°è¯·æ±‚): {new_url}")

    # --- 2. æå–å·²ç™»å½•çš„ Cookies ---
    current_cookies = tab.cookies()

    # å°† cookies è½¬æ¢ä¸ºå­—ç¬¦ä¸²å½¢å¼ï¼Œä½œä¸º HTTP è¯·æ±‚çš„å¤´éƒ¨
    cookies_str = "; ".join(
        [f"{cookie['name']}={cookie['value']}" for cookie in current_cookies]
    )

    # è®¾ç½® headersï¼Œå¸¦ä¸Š cookies
    headers = {"Cookie": cookies_str}

    # --- 3. ä½¿ç”¨ requests å‘é€è¯·æ±‚ ---
    try:
        response = requests.get(new_url, headers=headers, timeout=timeout)
    except requests.exceptions.RequestException as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
        return None

    # --- 4. æ£€æŸ¥å’Œæå–å“åº”ä½“ ---

    if response.status_code != 200:
        print(f"âŒ é‡æ–°è¯·æ±‚å¤±è´¥ï¼HTTP çŠ¶æ€ç : {response.status_code}")
        return None

    resp_body_text = response.text

    if not resp_body_text:
        print(f"âŒ é‡æ–°è¯·æ±‚æˆåŠŸ (200)ï¼Œä½†å“åº”ä½“ä¸ºç©ºã€‚")
        return None

    # --- 5. è§£æ JSON å’Œ Gzip è§£å‹ ---

    try:
        resp_json = json.loads(resp_body_text)
    except Exception as e:
        print(f"âš ï¸ å“åº”ä¸æ˜¯åˆæ³• JSONï¼š{e}\nåŸå§‹å†…å®¹: {resp_body_text[:200]}")
        return None

    # æå– gzip Base64 æ•°æ®
    try:
        gzip_base64_str = resp_json["data"]["records"]
    except KeyError:
        print("âŒ æœªæ‰¾åˆ° data.records å­—æ®µï¼Œè¯·æ£€æŸ¥è¿”å›ç»“æ„ã€‚")
        return None

    try:
        gzip_bytes = base64.b64decode(gzip_base64_str)
        with gzip.GzipFile(fileobj=BytesIO(gzip_bytes)) as f:
            decompressed_data = f.read().decode("utf-8")
        records_json = json.loads(decompressed_data)
    except Exception as e:
        print(f"âŒ è§£å‹æˆ–è§£æå¤±è´¥: {e}")
        return None

    print("âœ… æˆåŠŸè§£å‹ JSON æ•°æ®ï¼")
    return records_json, cookies_str


try:
    from selenium.webdriver.support import expected_conditions as EC
except Exception:
    EC = None


def normalize_text(s):
    if not s:
        return ""
    return s.replace('\u200b', '').strip()


def ensure_check_checkbox(driver, checkbox_id, timeout=10):
    """
    ç¨³å¥é€‰ä¸­ checkboxï¼šæ»šåŠ¨ã€ç‚¹å‡» label æˆ– inputï¼Œæˆ–åå¤‡è®¾ç½® checked å¹¶æ´¾å‘ changeã€‚
    """
    end_time = time.time() + timeout
    while time.time() < end_time:
        try:
            input_el = WebDriverWait(driver, 1).until(
                EC.presence_of_element_located((By.ID, checkbox_id))
            )
        except Exception:
            driver.execute_script("window.scrollBy(0, 400);")
            time.sleep(0.4)
            continue

        try:
            label = driver.find_element(By.CSS_SELECTOR, f"label[for=\"{checkbox_id}\"]")
        except Exception:
            label = None

        target = label if label is not None else input_el
        try:
            driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", target)
            driver.execute_script("window.scrollBy(0, -80);")
            time.sleep(0.25)
        except Exception:
            pass

        clicked = False
        if label:
            try:
                driver.execute_script("arguments[0].click();", label)
                clicked = True
            except Exception:
                clicked = False

        if not clicked:
            try:
                driver.execute_script("arguments[0].click();", input_el)
                clicked = True
            except Exception:
                clicked = False

        if not clicked:
            try:
                driver.execute_script(
                    "var el = document.getElementById(arguments[0]); if(el){ el.checked = true; el.dispatchEvent(new Event('change')); }",
                    checkbox_id
                )
            except Exception:
                pass

        try:
            is_checked = driver.execute_script(
                "var el = document.getElementById(arguments[0]); return !!(el && el.checked);", checkbox_id)
            if is_checked:
                print(f"âœ… å·²æˆåŠŸé€‰ä¸­ï¼š{checkbox_id}")
                return True
        except Exception:
            pass

        time.sleep(0.4)

    print(f"âŒ æ— æ³•é€‰ä¸­ {checkbox_id}ï¼ˆè¶…æ—¶ï¼‰")
    return False


def click_next_footer(driver, timeout=5):
    """åœ¨é¡µè„šç‚¹å‡»æ–‡æœ¬ä¸º Next çš„æŒ‰é’®"""
    end = time.time() + timeout
    while time.time() < end:
        buttons = driver.find_elements(By.CLASS_NAME, "card-footer-item")
        for btn in buttons:
            try:
                if btn.text.strip().lower() == "next":
                    btn.click()
                    return True
            except Exception:
                continue
        time.sleep(0.3)
    return False


def _toast_macos(message: str, title: str = "PrivacyTools") -> None:
    """macOS é€šçŸ¥ï¼ˆå¤±è´¥ä¹Ÿä¸å½±å“ä¸»æµç¨‹ï¼‰ã€‚"""
    try:
        if not message:
            return
        subprocess.run(
            ["osascript", "-e", f'display notification "{message}" with title "{title}"'],
            check=False,
            capture_output=True,
            text=True,
        )
    except Exception:
        pass


def _close_modal_if_possible(driver) -> None:
    """å°è¯•å…³é—­å¼¹çª—ï¼Œä¸è¡Œä¹Ÿä¸æŠ¥é”™ã€‚"""
    try:
        btns = driver.find_elements(By.CSS_SELECTOR, ".modal.is-active .delete")
        if btns:
            driver.execute_script("arguments[0].click();", btns[0])
            time.sleep(0.2)
    except Exception:
        pass


# 
# GitHub Pages / SSH helpers
# 


def _decode_bytes(b: bytes | None) -> str:
    """Decode subprocess output safely (avoid Windows GBK crashes)."""
    if not b:
        return ""
    try:
        return b.decode("utf-8", errors="replace")
    except Exception:
        return b.decode(errors="replace")


def _run_capture(cmd: list[str], *, env: dict | None = None, cwd: str | None = None) -> tuple[int, str, str]:
    """Run a command and capture stdout/stderr safely (bytes -> utf-8 replace)."""
    p = subprocess.run(cmd, env=env, cwd=cwd, capture_output=True)
    return p.returncode, _decode_bytes(p.stdout), _decode_bytes(p.stderr)


def ensure_github_ssh_keychain_ready(key_path: str = "~/.ssh/id_ed25519_common_hosts") -> None:
    """Teammate-friendly: don't spam `ssh-add` output and don't block on passphrase.

    We only *check* whether key is loaded. If not loaded, we print a one-time hint.
    Loading should be done manually once:
      ssh-add --apple-use-keychain ~/.ssh/id_ed25519_common_hosts
    """

    def _pub_key_body(pub_text: str) -> str:
        parts = (pub_text or "").strip().split()
        return parts[1] if len(parts) >= 2 else ""

    try:
        kp = Path(key_path).expanduser()
        if not kp.exists():
            return

        pub_path = Path(str(kp) + ".pub")
        if not pub_path.exists():
            return

        want_body = _pub_key_body(pub_path.read_text(encoding="utf-8"))
        if not want_body:
            return

        ret, out, _err = _run_capture(["ssh-add", "-L"])
        if ret == 0 and want_body in (out or ""):
            return

        print(
            "\nâš ï¸ æ£€æµ‹åˆ° GitHub Pages çš„ SSH key è¿˜æœªåŠ è½½åˆ° ssh-agentï¼ˆæˆ–æœªä¿å­˜åˆ° Keychainï¼‰ã€‚\n"
            "è¯·åœ¨ç»ˆç«¯æ‰‹åŠ¨æ‰§è¡Œä¸€æ¬¡ï¼ˆåªéœ€ä¸€æ¬¡ï¼‰ï¼š\n"
            f"  ssh-add --apple-use-keychain {kp}\n"
            "è¾“å…¥ passphrase åï¼Œä»¥åè„šæœ¬è¿è¡Œå°±ä¸ä¼šå†æç¤ºã€‚\n"
        )
    except Exception:
        pass


def _run_git_push_main_with_env() -> None:
    """Best-effort fallback push using the preferred SSH host alias.

    Note: We do NOT pass '-i key' here to avoid interactive passphrase prompts.
    Use ssh-agent+Keychain for non-interactive use.
    """
    env = os.environ.copy()
    env.setdefault("PRIVACY_PAGES_SSH_HOST", "github-common-hosts")

    env["GIT_SSH_COMMAND"] = (
        "ssh -o BatchMode=yes -o IdentitiesOnly=yes "
        "-o StrictHostKeyChecking=accept-new "
        "-o ControlMaster=auto -o ControlPersist=10m -o ControlPath=~/.ssh/cm-%r@%h:%p"
    )

    repo_root = Path(__file__).resolve().parent

    # push regardless of status (commit may already exist)
    subprocess.run(["git", "push", "origin", "main"], cwd=str(repo_root), env=env, check=False)


def publish_privacy_page_to_github(app_title: str, publish_id: str, content_file: Path) -> str:
    """Call googleSites.py to generate & push pages/<slug>/index.html.

    Return: published page URL (best-effort parsed).
    """
    env = os.environ.copy()
    env.setdefault("PRIVACY_PAGES_SSH_HOST", "github-common-hosts")
    env.setdefault("PRIVACY_PAGES_SSH_KEY", str(Path("~/.ssh/id_ed25519_common_hosts").expanduser()))

    safe_title = (app_title or "privacy-policy").strip() or "privacy-policy"
    safe_id = (publish_id or "").strip()

    cmd = [
        sys.executable,
        str(Path(__file__).resolve().parent / "googleSites.py"),
        "--title",
        safe_title,
        "--id",
        safe_id,
        "--content-file",
        str(content_file),
        "--commit-message",
        f"Publish privacy page: {safe_title}",
        "--no-wait",
    ]

    rc, stdout, stderr = _run_capture(cmd, env=env)
    combined = (stdout or "") + ("\n" + (stderr or "") if stderr else "")

    if combined.strip():
        print("------ googleSites.py è¾“å‡ºå¼€å§‹ ------")
        print(combined.strip())
        print("------ googleSites.py è¾“å‡ºç»“æŸ ------")

    m = re.search(r"(https?://[^\s]+/pages/[^\s]+/)", combined)
    page_url = m.group(1) if m else ""

    if rc != 0:
        print("âš ï¸ googleSites.py è¿”å›é 0ï¼Œå°è¯•å…œåº• push ä¸€æ¬¡...")
        try:
            _run_git_push_main_with_env()
        except Exception:
            pass

    return page_url


def extract_and_show_privacy_text(driver, wait_seconds=12, publish_id: str = ""):
    driver.switch_to.default_content()
    try:
        WebDriverWait(driver, wait_seconds).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, ".modal.is-active #privacy_simple_content"))
        )
    except Exception:
        print("âŒ æœªæ£€æµ‹åˆ°å¼¹çª—æˆ– privacy_simple_content")
        return None

    # ç›´æ¥è·å–å…ƒç´ çš„ innerHTML è€Œä¸æ˜¯æ•´é¡µ HTML
    try:
        inner_html = driver.execute_script(
            "var el=document.getElementById('privacy_simple_content');return el?el.innerHTML:'';"
        )
    except Exception as e:
        print(f"âŒ è·å– innerHTML å¤±è´¥: {e}")
        return None

    if not inner_html:
        print("âŒ privacy_simple_content.innerHTML ä¸ºç©º")
        return None

    text = html_to_formatted_text(inner_html)
    if not text:
        print("âŒ è§£æç»“æœä¸ºç©º")
        return None

    # 1) å¤åˆ¶éšç§æ–‡æœ¬åˆ°å‰ªè´´æ¿ + toast
    copy_to_clipboard_macos(text)
    _toast_macos("éšç§æ–‡æœ¬å·²å¤åˆ¶", title="PrivacyTools")

    # 2) å†™å‡ºåˆ°æ–‡ä»¶ç»™ GitHub Pages å‘å¸ƒç”¨
    try:
        PRIVACY_TEXT_OUT.write_text(text, encoding="utf-8")
        print(f"ğŸ“ å·²å†™å…¥éšç§æ–‡æœ¬åˆ°æ–‡ä»¶: {PRIVACY_TEXT_OUT}")
    except Exception as e:
        print(f"âš ï¸ å†™å…¥éšç§æ–‡æœ¬æ–‡ä»¶å¤±è´¥: {e}")

    # 3) æ§åˆ¶å°æ—¥å¿—è¾“å‡ºï¼ˆå¯æŸ¥ï¼‰
    print("------ Privacy Policy æ–‡æœ¬å¼€å§‹ ------")
    print(text)
    print("------ Privacy Policy æ–‡æœ¬ç»“æŸ ------")

    # 4) å¤åˆ¶å®Œæˆåå…³é—­ç½‘é¡µ/å¼¹çª—ï¼ˆå…ˆå…³ modalï¼Œå†å…³ tabï¼‰
    _close_modal_if_possible(driver)
    try:
        driver.close()
    except Exception:
        pass

    # 5) å‘å¸ƒåˆ° GitHub Pagesï¼šæ˜¾ç¤ºâ€œç½‘é¡µå‘å¸ƒä¸­...â€ï¼ŒæˆåŠŸåå¤åˆ¶ URL + toast
    publish_url = ""
    try:
        app_title = (app_name or "privacy-policy").strip() or "privacy-policy"
        print("ğŸš€ ç½‘é¡µå‘å¸ƒä¸­ã€‚ã€‚ã€‚å¤§æ¦‚åå‡ ç§’å§ã€‚ã€‚ã€‚")
        publish_url = publish_privacy_page_to_github(app_title=app_title, publish_id=publish_id, content_file=PRIVACY_TEXT_OUT)

        if publish_url:
            print(f"ğŸŒ å·²å‘å¸ƒç½‘é¡µåœ°å€: {publish_url}")
            copy_to_clipboard_macos(publish_url)
            _toast_macos("éšç§ç½‘é¡µé“¾æ¥å·²å¤åˆ¶", title="PrivacyTools")

            # 6) å‘å¸ƒæˆåŠŸåæ¸…ç†ä¸å†éœ€è¦çš„æ–‡ä»¶ï¼ˆæ ¹ç›®å½• index.html + privacy_text.txtï¼‰
            try:
                repo_root = Path(__file__).resolve().parent
                cleanup_paths = [repo_root / "index.html", repo_root / "privacy_text.txt"]
                for p in cleanup_paths:
                    if p.exists():
                        p.unlink()
                        print(f"ğŸ§¹ å·²åˆ é™¤æ— ç”¨æ–‡ä»¶: {p}")
            except Exception as e:
                print(f"âš ï¸ æ¸…ç†æ–‡ä»¶å¤±è´¥ï¼ˆå¯å¿½ç•¥ï¼‰: {e}")
        else:
            print("âš ï¸ æœªèƒ½ä»å‘å¸ƒè¾“å‡ºä¸­æå– URLï¼ˆä½†é€šå¸¸ä»å¯èƒ½å·²å‘å¸ƒæˆåŠŸï¼Œè¯·çœ‹ googleSites.py è¾“å‡ºï¼‰ã€‚")
    except Exception as e:
        print(f"âŒ å‘å¸ƒç½‘é¡µå¤±è´¥: {e}")

    return publish_url


def _replace_template_fields(template_html: str, app: str, creator: str, mail: str) -> str:
    """Replace key fields inside muban.html template.

    Replacements:
      1) In the first sentence: app name + created by name.
      2) Replace email occurrences in the whole template.

    Template keeps other content unchanged.
    """
    html_src = template_html or ""

    app_safe = html.escape(app or "", quote=True)
    creator_safe = html.escape(creator or "", quote=True)
    mail_safe = (mail or "").strip()

    # 1) Replace app name in the fixed phrase
    # Template line: "This privacy policy applies to the BeeKeeper Mania app (hereby referred to as ..."
    html_src = re.sub(
        r"(This privacy policy applies to\s+the\s+)(.+?)(\s+app\s*\(hereby referred to as &quot;Application&quot;\))",
        lambda m: m.group(1) + app_safe + m.group(3),
        html_src,
        count=1,
        flags=re.IGNORECASE | re.DOTALL,
    )

    # 2) Replace creator name in the fixed phrase
    html_src = re.sub(
        r"(for mobile devices that was created by\s+)(.+?)(\s+\(hereby referred to as &quot;Service Provider&quot;\))",
        lambda m: m.group(1) + creator_safe + m.group(3),
        html_src,
        count=1,
        flags=re.IGNORECASE | re.DOTALL,
    )

    # 3) Replace email everywhere (both plain and escaped forms)
    if mail_safe:
        old_emails = set(re.findall(r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}", html_src))
        for old in sorted(old_emails, key=len, reverse=True):
            html_src = html_src.replace(old, mail_safe)
            html_src = html_src.replace(html.escape(old, quote=True), html.escape(mail_safe, quote=True))

    return html_src


def _html_to_plain_text_for_clipboard(rendered_html: str) -> str:
    """Convert our template HTML (with <br> and simple tags) into readable plain text."""
    s = rendered_html or ""
    # Keep line breaks
    s = re.sub(r"<\s*br\s*/?\s*>", "\n", s, flags=re.IGNORECASE)
    # Strip all tags
    s = re.sub(r"<[^>]+>", "", s)
    # Unescape HTML entities
    s = html.unescape(s)
    # Normalize multiple blank lines
    s = re.sub(r"\n{3,}", "\n\n", s)
    return s.strip()


def generate_privacy_html_from_template() -> str:
    """Generate final privacy HTML by replacing fields in muban.html."""
    if not TEMPLATE_HTML_PATH.exists():
        raise FileNotFoundError(f"Template not found: {TEMPLATE_HTML_PATH}")

    template_html = TEMPLATE_HTML_PATH.read_text(encoding="utf-8")
    return _replace_template_fields(template_html, app=app_name or "", creator=company_name or "", mail=email or "")


def run_privacy_flow(driver, target_os="Android", publish_id: str = ""):
    """New flow: do NOT open privacy generator website.

    We already have app_name/company_name/email from the Lark pipeline.
    We render muban.html, replace key fields, copy plain text to clipboard,
    and publish the HTML to GitHub Pages.
    """

    # è®© target_os é»˜è®¤æ˜¯ Androidï¼ˆä¸”ä¿è¯ç±»å‹æ­£ç¡®ï¼‰
    if not isinstance(target_os, str):
        real_type = type(target_os).__name__
        print(f"âŒ target_os ç±»å‹é”™è¯¯ï¼ŒæœŸæœ›å­—ç¬¦ä¸²ï¼Œå®é™…ä¸º: {real_type}ï¼Œå°†å›é€€ä¸º Android")
        target_os = "Android"

    # 0) æ¸²æŸ“ muban.html æ¨¡æ¿
    try:
        rendered_html = generate_privacy_html_from_template()
    except Exception as e:
        print(f"âŒ æ¸²æŸ“æ¨¡æ¿å¤±è´¥: {e}")
        return False

    # 1) å¤åˆ¶çº¯æ–‡æœ¬åˆ°å‰ªè´´æ¿ï¼Œä¾›ç”¨æˆ·ç²˜è´´
    text_for_clipboard = _html_to_plain_text_for_clipboard(rendered_html)
    if text_for_clipboard:
        copy_to_clipboard_macos(text_for_clipboard)
        _toast_macos("éšç§æ–‡æœ¬å·²å¤åˆ¶", title="PrivacyTools")

    print("------ Privacy Policy æ–‡æœ¬ ------")
    print(text_for_clipboard)
    print("------ Privacy Policy æ–‡æœ¬ ------")

    # 2) å°† HTML å†™å…¥æ–‡ä»¶ï¼Œä¾› GitHub Pages å‘å¸ƒ
    try:
        PRIVACY_TEXT_OUT.write_text(rendered_html, encoding="utf-8")
        print(f"ğŸ“ å·²å†™å…¥éšç§æ–‡æœ¬åˆ°æ–‡ä»¶: {PRIVACY_TEXT_OUT}")
    except Exception as e:
        print(f"âš ï¸ å†™å…¥éšç§æ–‡æœ¬æ–‡ä»¶å¤±è´¥: {e}")

    # 3) å…³é—­ä»»ä½•å·²æ‰“å¼€çš„æµè§ˆå™¨ï¼ˆæ–°æµç¨‹ä¸å†éœ€è¦ï¼‰
    try:
        driver.quit()
    except Exception:
        pass

    # 4) å‘å¸ƒåˆ° GitHub Pagesï¼ˆé€»è¾‘ä¸ä¹‹å‰ç›¸åŒï¼‰
    publish_url = ""
    try:
        app_title = (app_name or "privacy-policy").strip() or "privacy-policy"
        print("ğŸš€ ç½‘é¡µå‘å¸ƒä¸­ã€‚ã€‚ã€‚å¤§æ¦‚åå‡ ç§’å§ã€‚ã€‚ã€‚")
        publish_url = publish_privacy_page_to_github(app_title=app_title, publish_id=publish_id, content_file=PRIVACY_TEXT_OUT)

        if publish_url:
            print(f"ğŸŒ å·²å‘å¸ƒç½‘é¡µåœ°å€: {publish_url}")
            copy_to_clipboard_macos(publish_url)
            _toast_macos("éšç§ç½‘é¡µé“¾æ¥å·²å¤åˆ¶", title="PrivacyTools")
        else:
            print("âš ï¸ æœªèƒ½ä»å‘å¸ƒè¾“å‡ºä¸­æå– URLï¼ˆä½†é€šå¸¸ä»å¯èƒ½å·²å‘å¸ƒæˆåŠŸï¼Œè¯·çœ‹ googleSites.py è¾“å‡ºï¼‰ã€‚")
    except Exception as e:
        print(f"âŒ å‘å¸ƒç½‘é¡µå¤±è´¥: {e}")

    return True



def find_and_collect_by_target_value(json_obj, target_value=None):
    """
    æŒ‰è®¢å•å·ç­›é€‰å¹¶åœ¨æ‰¾åˆ°æ—¶æŠŠ app_name å†™å…¥å…¨å±€å˜é‡ app_nameï¼Œç»§ç»­è¿”å›ç»“æœåˆ—è¡¨ã€‚
    """
    # é¡¶å±‚å‡½æ•°æœ¬èº«ä¸ç›´æ¥è¯»å†™ app_nameï¼Œåªåœ¨å†…éƒ¨åµŒå¥—å‡½æ•°é‡Œæ“ä½œ

    if not target_value:
        print("âŒ éœ€è¦æä¾› target_value (è®¢å•ç¼–å·)ï¼Œä¾‹å¦‚ 'IGT1185'")
        return []

    results = []
    target_str = str(target_value).strip().lower()

    def _search(obj):
        # è¿™é‡Œæ˜¾å¼å£°æ˜ä½¿ç”¨å…¨å±€ app_nameï¼Œé¿å… UnboundLocalError
        global app_name

        if isinstance(obj, dict):
            fld_order = obj.get("fldxQWjXD7")
            if isinstance(fld_order, dict):
                val = fld_order.get("value")
                if isinstance(val, list):
                    for entry in val:
                        if isinstance(entry, dict):
                            text = (entry.get("text") or "").strip()
                            if text.lower() == target_str:
                                # æå– app_nameï¼ˆæ¥è‡ª fldaShB3Gb çš„ç¬¬ä¸€ä¸ª value çš„ textï¼‰
                                found_app_name = None
                                flda = obj.get("fldaShB3Gb")
                                if isinstance(flda, dict):
                                    fval = flda.get("value")
                                    if isinstance(fval, list) and fval:
                                        first = fval[0]
                                        if isinstance(first, dict):
                                            found_app_name = (first.get("text") or "").strip() or None

                                # å°è¯•åœ¨ fldnLglcRi ä¸­å†™å…¥ app_name å¹¶è¿”å›å…¶ç¬¬ä¸€ä¸ª value
                                fldn = obj.get("fldnLglcRi")
                                if isinstance(fldn, dict):
                                    v = fldn.get("value")
                                    if isinstance(v, list) and v:
                                        first_item = v[0]
                                        if isinstance(first_item, dict):
                                            if found_app_name:
                                                first_item["app_name"] = found_app_name
                                            results.append(first_item)
                                        else:
                                            new_item = {"value": first_item}
                                            if found_app_name:
                                                new_item["app_name"] = found_app_name
                                            results.append(new_item)
                                    else:
                                        new_item = {}
                                        if found_app_name:
                                            new_item["app_name"] = found_app_name
                                        results.append(new_item)
                                else:
                                    if found_app_name:
                                        results.append({"app_name": found_app_name})
                                    else:
                                        results.append(obj)

                                # æ— è®ºä¹‹å‰æ˜¯å¦æœ‰å€¼ï¼Œç›´æ¥æŠŠæ‰¾åˆ°çš„ app_name èµ‹ç»™å…¨å±€å˜é‡
                                if found_app_name:
                                    app_name = found_app_name
                                    print(f"ğŸ”§ å·²è®¾ç½®å…¨å±€ app_name = `{app_name}`")

                                break

            # ç»§ç»­é€’å½’æŸ¥æ‰¾å­èŠ‚ç‚¹
            for v in obj.values():
                _search(v)

        elif isinstance(obj, list):
            for item in obj:
                _search(item)

    _search(json_obj)
    return results


def extract_vps_array_from_doc22(doc_data, cookies_str):
    global company_name, email
    print("ğŸ” æå–é¡µé¢ä¸­é¦–ä¸ªæœ‰æ•ˆçš„ @gmail.com é‚®ç®±...")
    results = []
    seen_urls = set()

    headers = {
        "Cookie": cookies_str or "",
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/123.0 Safari/537.36",
    }

    email_re = re.compile(r'(?<![A-Za-z0-9._%+\-])([A-Za-z0-9._%+\-]+@gmail\.com)\b', re.I)

    def _clean_gmail_emails(raw_text):
        found = email_re.findall(raw_text or "")
        unique = []
        seen = set()
        for e in found:
            ne = e.strip().lower()
            if ne and ne not in seen:
                seen.add(ne)
                unique.append(ne)
        final = []
        sset = set(unique)
        for e in unique:
            if len(e) > 1 and e[1:] in sset and len(e[0]) == 1:
                continue
            final.append(e)
        return final

    for item in doc_data:
        url = item.get("link")
        text = item.get("text", "")
        if not url and not text:
            continue
        if url in seen_urls:
            continue

        try:
            response = requests.get(url, headers=headers, timeout=15)
            if response.status_code != 200:
                print(f"âŒ è¯·æ±‚å¤±è´¥: {url}, çŠ¶æ€ç : {response.status_code}")
                continue

            page_content = html.unescape(response.text or "")
            emails = _clean_gmail_emails(page_content)
            primary = emails[0] if emails else ""

            # é¦–æ¬¡å‘ç°æ—¶ï¼Œè®¾ç½®å…¨å±€ company_name å’Œ emailï¼ˆå¦‚æœå°šæœªè®¾ç½®ï¼‰
            if not company_name:
                t = (text or "").strip()
                m = re.search(r'-(.+)$', t)
                if m:
                    company_name = m.group(1).strip()
                else:
                    parts = t.split(None, 1)
                    company_name = parts[1].strip() if len(parts) > 1 else (t or "")

            if primary and not email:
                email = primary.strip().lower()

            results.append(
                {
                    "text": text,
                    "url": url,
                    "email": primary,
                }
            )
            seen_urls.add(url)

        except Exception as e:
            print(f"âŒ è§£æå¤±è´¥: {url}, é”™è¯¯: {e}")

        # å¦‚æœå…¨å±€ä¿¡æ¯éƒ½å·²å¡«å……ï¼Œå¯ä»¥é€‰æ‹©æå‰é€€å‡ºä»¥åŠ å¿«é€Ÿåº¦
        if company_name and email:
            break

    # æŒ‰ text ä¸­çš„æ•°å­—æ’åºï¼ˆä¿æŒåŸæœ‰è¡Œä¸ºï¼‰
    def _extract_number(t):
        m = re.search(r"(\d+)", (t or ""))
        return int(m.group(1)) if m else 0

    results.sort(key=lambda x: _extract_number(x.get("text")))

    for item in results:
        print(f"{item.get('text')}")
        if item.get('email'):
            print(f"  é‚®ç®±: {item.get('email')}")
        else:
            print("  é‚®ç®±: æœªå‘ç° @gmail.com åœ°å€")
        print("-" * 50)

    print(f"âœ… æ€»æ•°é‡: {len(results)}")
    return results


def save_to_json(data, filename="none.json"):
    Path(filename).write_text(json.dumps(data, ensure_ascii=False, indent=2))
    # print(f"âœ… å·²ä¿å­˜ {len(data)} æ¡ç»“æœåˆ° {filename}")


import argparse


if __name__ == "__main__":
    # åœ¨è¿è¡Œ push ä¹‹å‰åªåšä¸€æ¬¡æ£€æŸ¥ï¼šå¦‚æœ key æ²¡åŠ è½½ï¼Œä¼šæç¤ºåŒäº‹æ‰§è¡Œä¸€æ¬¡ ssh-add
    ensure_github_ssh_keychain_ready()

    parser = argparse.ArgumentParser()
    parser.add_argument('id', nargs='?', help='è¡¨æ ¼ä¸­æŸ¥æ‰¾çš„ç¼–å·ï¼Œä¾‹å¦‚ IGT1128')
    args = parser.parse_args()

    # äº¤äº’è·å– idï¼ˆè‹¥æœªé€šè¿‡å‘½ä»¤è¡Œæä¾›ï¼‰
    if not args.id:
        try:
            args.id = input("è¯·è¾“å…¥ç¼–å·ï¼ˆä¾‹å¦‚ IGT1128ï¼‰ï¼š").strip()
        except (EOFError, KeyboardInterrupt):
            args.id = None

    if not args.id:
        print("âŒ æœªæä¾›ç¼–å·ï¼Œè„šæœ¬å°†é€€å‡ºã€‚\nç¤ºä¾‹ç”¨æ³•ï¼špython privacys.py IGT1128 --scan")
        sys.exit(2)

    try:
        records, cookies_str = get_gzip_json_from_api()
        if not records:
            print("âŒ æœªèƒ½è·å– recordsï¼Œè„šæœ¬é€€å‡º")
            sys.exit(1)

        available_records = find_and_collect_by_target_value(records, target_value=args.id)
        vps_result = extract_vps_array_from_doc22(available_records, cookies_str)

        driver = create_driver()
        run_privacy_flow(driver=driver, target_os="Android", publish_id=args.id)
    finally:
        if driver is not None:
            try:
                driver.quit()
            except Exception:
                pass
