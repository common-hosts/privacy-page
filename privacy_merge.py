import html
import sys
import urllib
import subprocess
import os

import requests
from selenium import webdriver
import time
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
from selenium.webdriver.support.wait import WebDriverWait

import base64
import gzip
import json
import re
from io import BytesIO
from pathlib import Path
from DrissionPage import Chromium

PRIVACY_GEN_URL = "https://app-privacy-policy-generator.firebaseapp.com/"
table_url = "https://superxgr.larksuite.com/base/SebGbrq2yaNXXSsVOcJudpzxsCf?table=tblTywpT1yCgOaV7&view=vewOnkM00z"
api_keyword = "SebGbrq2yaNXXSsVOcJudpzxsCf/records"
browser = None
browser_port = 9527
cookies_str = ""
app_name: str = ""
company_name: str = ""
email: str = ""

# ç”¨äº finally å®‰å…¨é€€å‡º
driver = None

# ç”Ÿæˆå¹¶å‘å¸ƒé™æ€é¡µéœ€è¦çš„è¾“å‡ºæ–‡ä»¶
PRIVACY_TEXT_OUT = Path(__file__).resolve().parent / "privacy_text.txt"


def html_to_formatted_text(html_fragment: str) -> str:
    """å°† privacy_simple_content çš„ innerHTML è½¬æˆè¾ƒå¥½ç²˜è´´çš„çº¯æ–‡æœ¬ï¼Œä¿ç•™æ®µè½ã€åˆ—è¡¨å’Œé“¾æ¥ç»“æ„ã€‚"""
    if not html_fragment:
        return ""
    soup = BeautifulSoup(html_fragment, "html.parser")

    lines = []

    from bs4.element import NavigableString, Tag

    def handle_node(node, indent_level=0):
        indent = "  " * indent_level

        if isinstance(node, NavigableString):
            text = str(node)
            text = text.replace("\u200b", "").strip("\n")
            if text:
                lines.append(indent + text)
            return

        if not isinstance(node, Tag):
            return

        name = (node.name or "").lower()

        if name == "br":
            lines.append("")
            return

        if name in {"p", "div", "section", "strong", "b", "em", "i", "h1", "h2", "h3", "h4", "h5", "h6"}:
            before = len(lines)
            for child in node.children:
                handle_node(child, indent_level)
            after = len(lines)
            if after > before and (not lines or lines[-1] != ""):
                lines.append("")
            return

        if name in {"ul", "ol"}:
            if lines and lines[-1] != "":
                lines.append("")
            idx = 1
            for li in node.find_all("li", recursive=False):
                prefix = "- " if name == "ul" else f"{idx}. "
                buf = []

                def collect(child):
                    if isinstance(child, NavigableString):
                        t = str(child).replace("\u200b", "").strip("\n")
                        if t:
                            buf.append(t)
                    elif isinstance(child, Tag):
                        cname = (child.name or "").lower()
                        if cname == "br":
                            buf.append(" ")
                        elif cname == "a":
                            href = child.get("href") or ""
                            visible = child.get_text(strip=True)
                            if href and visible:
                                buf.append(f"{visible} ({href})")
                            else:
                                buf.append(visible or href)
                        else:
                            for g in child.children:
                                collect(g)

                for c in li.children:
                    collect(c)
                li_text = "".join(buf)
                li_text = re.sub(r"\s+", " ", li_text).strip()
                if li_text:
                    lines.append(indent + prefix + li_text)
                for sub in li.find_all(["ul", "ol"], recursive=False):
                    handle_node(sub, indent_level + 1)
                if lines and lines[-1] != "":
                    lines.append("")
                idx += 1
            return

        if name == "a":
            href = node.get("href") or ""
            visible = node.get_text(strip=True)
            if href and visible:
                lines.append(indent + f"{visible} ({href})")
            else:
                lines.append(indent + (visible or href))
            return

        for child in node.children:
            handle_node(child, indent_level)

    root = soup.find(id="privacy_simple_content") or soup
    for c in root.children:
        handle_node(c, 0)

    out = []
    blank = 0
    for ln in lines:
        if ln.strip() == "":
            blank += 1
            if blank <= 2:
                out.append("")
        else:
            blank = 0
            out.append(ln)

    text = "\n".join(out)
    text = text.replace("\r\n", "\n")
    text = re.sub(r"\n{3,}", "\n\n", text).strip()
    return text


def copy_to_clipboard_macos(text: str) -> bool:
    """åœ¨ macOS ä½¿ç”¨ pbcopy å¤åˆ¶æ–‡æœ¬åˆ°ç³»ç»Ÿå‰ªè´´æ¿ã€‚"""
    if not text:
        return False
    try:
        subprocess.run(["pbcopy"], input=text.encode("utf-8"), check=True)
        print("âœ… å·²å¤åˆ¶åˆ°ç³»ç»Ÿå‰ªè´´æ¿ (pbcopy)")
        return True
    except Exception as e:
        print(f"âš ï¸ å¤åˆ¶åˆ°å‰ªè´´æ¿å¤±è´¥: {e}")
        return False


def get_gzip_json_from_api(timeout: int = 60):
    """
    1. ç›‘å¬æ¥å£æ•è·åŠ¨æ€å‚æ•°ã€‚
    2. æ‰‹åŠ¨æ‰«ç ç™»å½•ï¼Œåˆ·æ–°é¡µé¢è§¦å‘æ¥å£ã€‚
    3. ä¿®æ”¹æ•è·åˆ°çš„ URLï¼Œè®¾ç½® offset=0ã€‚
    4. æå– Cookiesï¼Œä½¿ç”¨ requests åº“é‡æ–°å‘é€è¯·æ±‚ã€‚
    5. è§£æå“åº”ï¼Œè§£å‹ Gzip æ•°æ®ã€‚
    """
    global browser
    if browser is None:
        browser = Chromium(browser_port)

    tab = browser.latest_tab
    tab.get(table_url)
    print(f"ğŸ” å¼€å§‹ç›‘å¬æ¥å£: {api_keyword}")
    tab.listen.start(api_keyword)

    input("è¯·æ‰«ç ç™»å½•å¹¶æŒ‰ Enter ç»§ç»­ >>> ")
    tab.refresh()  # è§¦å‘æ¥å£è¯·æ±‚

    print(f"ğŸ” å¼€å§‹æ•è·æ¥å£è¯·æ±‚...")
    # ç­‰å¾…æ¥å£è§¦å‘
    req = tab.listen.wait(timeout=timeout)
    tab.listen.stop()  # æ•è·åˆ°ååœæ­¢ç›‘å¬

    if not req:
        print(f"âŒ {timeout} ç§’å†…æœªæ•è·åˆ°æ¥å£è¯·æ±‚ã€‚")
        return None

    # --- 1. è·å–åŸå§‹ URL å¹¶ä¿®æ”¹ offset ---
    original_url = req.url
    print(f"âœ… æ•è·åˆ°åŸå§‹æ¥å£: {original_url}")

    # è§£æ URL å’ŒæŸ¥è¯¢å‚æ•°
    parsed_url = urllib.parse.urlparse(original_url)
    query_params = urllib.parse.parse_qs(parsed_url.query)

    # ä¿®æ”¹ offset å‚æ•°ä¸º 0ï¼ˆè·å–æ‰€æœ‰æ•°æ®ï¼‰
    query_params["offset"] = ["0"]

    # é‡æ–°æ„å»ºæŸ¥è¯¢å­—ç¬¦ä¸²å’Œå®Œæ•´çš„ URL
    new_query_string = urllib.parse.urlencode(query_params, doseq=True)
    new_url = urllib.parse.urlunparse(parsed_url._replace(query=new_query_string))

    print(f"ğŸ”„ æ­£åœ¨ç”¨ä¿®æ”¹åçš„ URL (åå°è¯·æ±‚): {new_url}")

    # --- 2. æå–å·²ç™»å½•çš„ Cookies ---
    current_cookies = tab.cookies()

    # å°† cookies è½¬æ¢ä¸ºå­—ç¬¦ä¸²å½¢å¼ï¼Œä½œä¸º HTTP è¯·æ±‚çš„å¤´éƒ¨
    cookies_str = "; ".join(
        [f"{cookie['name']}={cookie['value']}" for cookie in current_cookies]
    )

    # è®¾ç½® headersï¼Œå¸¦ä¸Š cookies
    headers = {"Cookie": cookies_str}

    # --- 3. ä½¿ç”¨ requests å‘é€è¯·æ±‚ ---
    try:
        response = requests.get(new_url, headers=headers, timeout=timeout)
    except requests.exceptions.RequestException as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
        return None

    # --- 4. æ£€æŸ¥å’Œæå–å“åº”ä½“ ---

    if response.status_code != 200:
        print(f"âŒ é‡æ–°è¯·æ±‚å¤±è´¥ï¼HTTP çŠ¶æ€ç : {response.status_code}")
        return None

    resp_body_text = response.text

    if not resp_body_text:
        print(f"âŒ é‡æ–°è¯·æ±‚æˆåŠŸ (200)ï¼Œä½†å“åº”ä½“ä¸ºç©ºã€‚")
        return None

    # --- 5. è§£æ JSON å’Œ Gzip è§£å‹ ---

    try:
        resp_json = json.loads(resp_body_text)
    except Exception as e:
        print(f"âš ï¸ å“åº”ä¸æ˜¯åˆæ³• JSONï¼š{e}\nåŸå§‹å†…å®¹: {resp_body_text[:200]}")
        return None

    # æå– gzip Base64 æ•°æ®
    try:
        gzip_base64_str = resp_json["data"]["records"]
    except KeyError:
        print("âŒ æœªæ‰¾åˆ° data.records å­—æ®µï¼Œè¯·æ£€æŸ¥è¿”å›ç»“æ„ã€‚")
        return None

    try:
        gzip_bytes = base64.b64decode(gzip_base64_str)
        with gzip.GzipFile(fileobj=BytesIO(gzip_bytes)) as f:
            decompressed_data = f.read().decode("utf-8")
        records_json = json.loads(decompressed_data)
    except Exception as e:
        print(f"âŒ è§£å‹æˆ–è§£æå¤±è´¥: {e}")
        return None

    print("âœ… æˆåŠŸè§£å‹ JSON æ•°æ®ï¼")
    return records_json, cookies_str


try:
    from selenium.webdriver.support import expected_conditions as EC
except Exception:
    EC = None


def normalize_text(s):
    if not s:
        return ""
    return s.replace('\u200b', '').strip()


def ensure_check_checkbox(driver, checkbox_id, timeout=10):
    """
    ç¨³å¥é€‰ä¸­ checkboxï¼šæ»šåŠ¨ã€ç‚¹å‡» label æˆ– inputï¼Œæˆ–åå¤‡è®¾ç½® checked å¹¶æ´¾å‘ changeã€‚
    """
    end_time = time.time() + timeout
    while time.time() < end_time:
        try:
            input_el = WebDriverWait(driver, 1).until(
                EC.presence_of_element_located((By.ID, checkbox_id))
            )
        except Exception:
            driver.execute_script("window.scrollBy(0, 400);")
            time.sleep(0.4)
            continue

        try:
            label = driver.find_element(By.CSS_SELECTOR, f"label[for=\"{checkbox_id}\"]")
        except Exception:
            label = None

        target = label if label is not None else input_el
        try:
            driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", target)
            driver.execute_script("window.scrollBy(0, -80);")
            time.sleep(0.25)
        except Exception:
            pass

        clicked = False
        if label:
            try:
                driver.execute_script("arguments[0].click();", label)
                clicked = True
            except Exception:
                clicked = False

        if not clicked:
            try:
                driver.execute_script("arguments[0].click();", input_el)
                clicked = True
            except Exception:
                clicked = False

        if not clicked:
            try:
                driver.execute_script(
                    "var el = document.getElementById(arguments[0]); if(el){ el.checked = true; el.dispatchEvent(new Event('change')); }",
                    checkbox_id
                )
            except Exception:
                pass

        try:
            is_checked = driver.execute_script(
                "var el = document.getElementById(arguments[0]); return !!(el && el.checked);", checkbox_id)
            if is_checked:
                print(f"âœ… å·²æˆåŠŸé€‰ä¸­ï¼š{checkbox_id}")
                return True
        except Exception:
            pass

        time.sleep(0.4)

    print(f"âŒ æ— æ³•é€‰ä¸­ {checkbox_id}ï¼ˆè¶…æ—¶ï¼‰")
    return False


def click_next_footer(driver, timeout=5):
    """åœ¨é¡µè„šç‚¹å‡»æ–‡æœ¬ä¸º Next çš„æŒ‰é’®"""
    end = time.time() + timeout
    while time.time() < end:
        buttons = driver.find_elements(By.CLASS_NAME, "card-footer-item")
        for btn in buttons:
            try:
                if btn.text.strip().lower() == "next":
                    btn.click()
                    return True
            except Exception:
                continue
        time.sleep(0.3)
    return False


def publish_privacy_page_to_github(app_title: str, publish_id: str, content_file: Path) -> str:
    """è°ƒç”¨ googleSites.pyï¼ŒæŠŠæœ¬åœ°ç”Ÿæˆçš„ pages/<slug>/index.html æ¨é€åˆ°è¿œç«¯å¹¶ç­‰å¾…å¯è®¿é—®ã€‚

    è¿”å›ï¼šå‘å¸ƒåçš„ page_urlï¼ˆå°½æœ€å¤§åŠªåŠ›ä»è¾“å‡ºä¸­æå–ï¼‰ã€‚
    """
    env = os.environ.copy()
    env.setdefault("PRIVACY_PAGES_SSH_HOST", "github-common-hosts")
    env.setdefault("PRIVACY_PAGES_SSH_KEY", str(Path("~/.ssh/id_ed25519_common_hosts").expanduser()))

    safe_title = (app_title or "privacy-policy").strip() or "privacy-policy"
    safe_id = (publish_id or "").strip()

    cmd = [
        sys.executable,
        str(Path(__file__).resolve().parent / "googleSites.py"),
        "--title",
        safe_title,
        "--id",
        safe_id,
        "--content-file",
        str(content_file),
        "--commit-message",
        f"Publish privacy page: {safe_title}",
    ]

    p = subprocess.run(cmd, env=env, text=True, capture_output=True)
    combined = (p.stdout or "") + ("\n" + (p.stderr or "") if p.stderr else "")

    # æŠŠ googleSites.py çš„è¾“å‡ºä¹Ÿæ‰“å°å‡ºæ¥ï¼Œé¿å…â€œå¤åˆ¶åæ²¡ååº”â€
    if combined.strip():
        print("------ googleSites.py è¾“å‡ºå¼€å§‹ ------")
        print(combined.strip())
        print("------ googleSites.py è¾“å‡ºç»“æŸ ------")

    # ä»è¾“å‡ºé‡Œæå– URLï¼ˆgoogleSites.py ä¼šæ‰“å° ğŸŒ Page URL: ...ï¼‰
    m = re.search(r"(https?://[^\s]+/pages/[^\s]+/)", combined)
    page_url = m.group(1) if m else ""

    # å¦‚æœ googleSites.py æ²¡èƒ½æˆåŠŸ push æˆ–è€…ä½ åœ¨ IDE é‡Œåªæäº¤æœª pushï¼Œä¼šå¯¼è‡´æ–°ç›®å½•ä¸åœ¨è¿œç«¯ -> 404
    # æ‰€ä»¥è¿™é‡Œå†å…œåº•æ£€æŸ¥ä¸€æ¬¡ï¼šå¦‚æœæœ¬åœ°é¢†å…ˆ origin/mainï¼Œå°±å¼ºåˆ¶ pushã€‚
    try:
        cnt = subprocess.run(
            ["git", "rev-list", "--left-right", "--count", "origin/main...HEAD"],
            cwd=str(Path(__file__).resolve().parent),
            text=True,
            capture_output=True,
        )
        if cnt.returncode == 0:
            parts = (cnt.stdout or "").strip().split()
            if len(parts) == 2:
                behind, ahead = int(parts[0]), int(parts[1])
                if ahead > 0:
                    print(f"ğŸ” æ£€æµ‹åˆ°æœ¬åœ°æœ‰ {ahead} ä¸ªæäº¤æœªæ¨é€ï¼Œè‡ªåŠ¨æ‰§è¡Œ git push...")
                    subprocess.run(["git", "push", "origin", "main"], cwd=str(Path(__file__).resolve().parent), check=False)
    except Exception:
        pass

    if p.returncode != 0:
        print("âŒ è‡ªåŠ¨å‘å¸ƒåˆ° GitHub Pages å¤±è´¥ï¼ˆgoogleSites.py è¿”å›é 0ï¼‰ã€‚")
        # fallbackï¼šè‡³å°‘æŠŠæœ¬åœ°æäº¤æ¨åˆ°è¿œç«¯ï¼Œé¿å…ç”¨æˆ·è¯¯ä»¥ä¸ºå·²å‘å¸ƒ
        print("ğŸ” fallbackï¼šå°è¯•æ‰§è¡Œä¸€æ¬¡ `git push origin main`...")
        try:
            subprocess.run(["git", "push", "origin", "main"], cwd=str(Path(__file__).resolve().parent), check=False)
        except Exception:
            pass

    return page_url


# python
def extract_and_show_privacy_text(driver, wait_seconds=12, publish_id: str = ""):
    driver.switch_to.default_content()
    try:
        WebDriverWait(driver, wait_seconds).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, ".modal.is-active #privacy_simple_content"))
        )
    except Exception:
        print("âŒ æœªæ£€æµ‹åˆ°å¼¹çª—æˆ– privacy_simple_content")
        return None

    # ç›´æ¥è·å–å…ƒç´ çš„ innerHTML è€Œä¸æ˜¯æ•´é¡µ HTML
    try:
        inner_html = driver.execute_script(
            "var el=document.getElementById('privacy_simple_content');return el?el.innerHTML:'';"
        )
    except Exception as e:
        print(f"âŒ è·å– innerHTML å¤±è´¥: {e}")
        return None

    if not inner_html:
        print("âŒ privacy_simple_content.innerHTML ä¸ºç©º")
        return None

    text = html_to_formatted_text(inner_html)
    if not text:
        print("âŒ è§£æç»“æœä¸ºç©º")
        return None

    # å°è¯•å¤åˆ¶åˆ°ç³»ç»Ÿå‰ªè´´æ¿
    copy_to_clipboard_macos(text)

    # åŒæ—¶å†™å‡ºåˆ°æ–‡ä»¶ï¼Œæ–¹ä¾¿åç»­ GitHub Pages å‘å¸ƒ
    try:
        PRIVACY_TEXT_OUT.write_text(text, encoding="utf-8")
        print(f"ğŸ“ å·²å†™å…¥éšç§æ–‡æœ¬åˆ°æ–‡ä»¶: {PRIVACY_TEXT_OUT}")
    except Exception as e:
        print(f"âš ï¸ å†™å…¥éšç§æ–‡æœ¬æ–‡ä»¶å¤±è´¥: {e}")

    driver.execute_script(
        """
        (function(value){
            let ta = document.getElementById('privacy_plain_textarea');
            if(!ta){
                ta = document.createElement('textarea');
                ta.id = 'privacy_plain_textarea';
                Object.assign(ta.style,{
                    position:'fixed',right:'20px',top:'20px',width:'520px',height:'600px',
                    whiteSpace:'pre-wrap',zIndex:2147483647,fontSize:'12px',padding:'8px',
                    background:'#fff',border:'1px solid rgba(0,0,0,0.2)',boxShadow:'0 2px 8px rgba(0,0,0,0.15)',
                    resize:'both'
                });
                ta.onclick=function(){this.select();};
                document.body.appendChild(ta);
            }
            ta.value=value;
            ta.style.display='block';
            ta.focus();
            ta.select();
            let copied=false;
            try{document.execCommand('copy');copied=true;}catch(e){console.warn('copy failed',e);}
            if(copied){
                let toast=document.getElementById('privacy_copy_toast');
                if(!toast){
                    toast=document.createElement('div');
                    toast.id='privacy_copy_toast';
                    Object.assign(toast.style,{
                        position:'fixed',bottom:'30px',right:'30px',padding:'10px 18px',
                        background:'rgba(0,0,0,0.8)',color:'#fff',borderRadius:'6px',
                        fontSize:'14px',zIndex:2147483647,transition:'opacity 0.3s'
                    });
                    document.body.appendChild(toast);
                }
                toast.textContent='éšç§æ–‡æœ¬å·²å¤åˆ¶';
                toast.style.opacity='1';
                setTimeout(()=>{toast.style.opacity='0';},2000);
            }
            console.log('PRIVACY_PLAIN_TEXT_START\\n'+value+'\\nPRIVACY_PLAIN_TEXT_END');
        })(arguments[0]);
        """,
        text,
    )

    print("------ Privacy Policy æ–‡æœ¬å¼€å§‹ ------")
    print(text)
    print("------ Privacy Policy æ–‡æœ¬ç»“æŸ ------")
    print("------ å·²å¤åˆ¶åˆ°ç³»ç»Ÿå‰ªè´´æ¿ (pbcopy) ------")

    # å¯é€‰ï¼šè‡ªåŠ¨å‘å¸ƒåˆ° GitHub Pagesï¼ˆä¾èµ– googleSites.py + git push SSHï¼‰
    try:
        app_title = (app_name or "privacy-policy").strip() or "privacy-policy"
        print("ğŸš€ ç½‘é¡µå‘å¸ƒä¸­ã€‚ã€‚ã€‚")
        publish_url = publish_privacy_page_to_github(app_title, publish_id, PRIVACY_TEXT_OUT)
        if publish_url:
            print(f"ğŸŒ å·²å‘å¸ƒç½‘é¡µåœ°å€: {publish_url}")

            # å†æŠŠæœ€ç»ˆ URL å¤åˆ¶ä¸€æ¬¡ï¼Œç¡®ä¿ç”¨æˆ·éšæ‰‹å¯ç²˜è´´
            try:
                copy_to_clipboard_macos(publish_url)
                try:
                    subprocess.run(
                        ["osascript", "-e", 'display notification "éšç§ç½‘é¡µé“¾æ¥å·²å¤åˆ¶" with title "PrivacyTools"'],
                        check=False,
                        capture_output=True,
                        text=True,
                    )
                except Exception:
                    pass
            except Exception:
                pass
        else:
            print("âš ï¸ æœªèƒ½ä»å‘å¸ƒè¾“å‡ºä¸­æå– URLï¼ˆä½†é€šå¸¸ä»å¯èƒ½å·²å‘å¸ƒæˆåŠŸï¼Œè¯·çœ‹ googleSites.py è¾“å‡ºï¼‰ã€‚")
    except Exception as e:
        print(f"âš ï¸ è‡ªåŠ¨å‘å¸ƒåˆ° GitHub Pages å¤±è´¥ï¼ˆä¸å½±å“åç»­æµç¨‹ï¼‰: {e}")

    # å¤åˆ¶æ–‡æœ¬å®Œæˆåï¼Œè‡ªåŠ¨å…³é—­ç½‘é¡µçª—å£ï¼ˆä¸å…³é—­æ•´ä¸ªè„šæœ¬ï¼‰
    try:
        driver.close()
    except Exception:
        pass

    return text


def run_privacy_flow(driver, target_os="Android", publish_id: str = ""):
    """
    æ‰§è¡Œéšç§ç”Ÿæˆæµç¨‹ï¼ˆåŸºäº app-privacy-policy-generatorï¼‰ã€‚

    :param driver: selenium WebDriver å®ä¾‹
    :param target_os: ç›®æ ‡ OS å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ "iOS" / "Android"
    """
    global app_name, company_name, email

    # é˜²æ­¢æŠŠ WebDriver æˆ–å…¶å®ƒå¯¹è±¡å½“æˆ target_os ä¼ è¿›æ¥
    if not isinstance(target_os, str):
        real_type = type(target_os).__name__
        print(f"âŒ target_os ç±»å‹é”™è¯¯ï¼ŒæœŸæœ›å­—ç¬¦ä¸²ï¼Œå®é™…ä¸º: {real_type}")
        # å°è¯•å›é€€åˆ°é»˜è®¤å€¼
        target_os = "Android"

    target_os = (target_os or "").strip()
    if not target_os:
        print("âŒ target_os ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œä½¿ç”¨é»˜è®¤ 'Android'")
        target_os = "Android"

    driver.get(PRIVACY_GEN_URL)
    try:
        WebDriverWait(driver, 15).until(
            EC.element_to_be_clickable((By.CLASS_NAME, "start-btn"))
        ).click()
    except Exception:
        pass

    # ç­‰å¾… appName è¾“å…¥å‡ºç°
    WebDriverWait(driver, 15).until(
        EC.presence_of_element_located((By.ID, "appName"))
    )
    driver.find_element(By.ID, "appName").clear()
    driver.find_element(By.ID, "appName").send_keys(app_name or "")
    driver.find_element(By.ID, "appContact").clear()
    driver.find_element(By.ID, "appContact").send_keys(email or "")
    time.sleep(0.2)
    click_next_footer(driver)

    # ç»§ç»­ç‚¹å‡» Nextï¼ˆå¯èƒ½éœ€è¦å¤šæ­¥ï¼‰
    time.sleep(0.2)
    click_next_footer(driver)
    time.sleep(0.2)

    # é€‰æ‹© Mobile OS
    radios = driver.find_elements(By.CSS_SELECTOR, 'input[type="radio"]')
    chosen = False
    for r in radios:
        try:
            val = (r.get_attribute("value") or "").strip()
            if val and val.lower() == target_os.lower():
                driver.execute_script(
                    "arguments[0].scrollIntoView({block:'center'});", r
                )
                r.click()
                chosen = True
                print(f"âœ… å·²é€‰æ‹© Mobile OS: {target_os}")
                break
        except Exception:
            continue
    if not chosen:
        # æ‰“å°é¡µé¢é‡Œå®é™…å¯ç”¨çš„ valueï¼Œæ–¹ä¾¿æ’æŸ¥
        available = []
        for r in radios:
            try:
                v = (r.get_attribute("value") or "").strip()
                if v:
                    available.append(v)
            except Exception:
                continue
        print(
            f"âŒ æ²¡æœ‰æ‰¾åˆ° OS é€‰é¡¹: {target_os}ï¼Œé¡µé¢å¯ç”¨é€‰é¡¹: {available or '[]'}"
        )

    time.sleep(0.2)
    click_next_footer(driver)
    time.sleep(0.2)

    # å¡«å†™ Company Name
    dev_input = driver.find_elements(By.ID, "devName")
    if dev_input:
        el = dev_input[0]
        el.clear()
        el.send_keys(company_name or "")
        print("âœ… å·²å¡«å†™ Company Name")
    time.sleep(0.2)
    click_next_footer(driver)
    time.sleep(0.2)

    # å‹¾é€‰ç¬¬ä¸‰æ–¹æœåŠ¡ï¼ˆç¤ºä¾‹ id åˆ—è¡¨ï¼Œå¯ä»¥æ ¹æ®é¡µé¢å®é™… id è°ƒæ•´ï¼‰
    third_party_ids = [
        "list-switch-Google Analytics for Firebase",
        "list-switch-Firebase Crashlytics",
        "list-switch-Adjust",
    ]
    for cid in third_party_ids:
        ensure_check_checkbox(driver, cid, timeout=6)
        time.sleep(0.2)

    # Next -> Privacy Policy
    time.sleep(0.2)
    click_next_footer(driver)
    time.sleep(0.2)

    # ç‚¹å‡» Privacy Policy æŒ‰é’®
    footer_links = driver.find_elements(By.CLASS_NAME, "card-footer-item")
    clicked_priv = False
    for link in footer_links:
        try:
            if link.text.strip().lower() == "privacy policy":
                link.click()
                clicked_priv = True
                print("âœ… å·²ç‚¹å‡» Privacy Policy")
                break
        except Exception:
            continue
    if not clicked_priv:
        print("âŒ æ²¡æœ‰æ‰¾åˆ° Privacy Policy æŒ‰é’®")
    extract_and_show_privacy_text(driver, publish_id=publish_id)
    # return True


# def create_driver(headless=False, user_data_dir=None, profile_dir=None):
#     opts = webdriver.ChromeOptions()
#     opts.add_argument('--start-maximized')
#     if headless:
#         opts.add_argument('--headless=new')
#     if user_data_dir:
#         opts.add_argument(f'--user-data-dir={user_data_dir}')
#     if profile_dir:
#         opts.add_argument(f'--profile-directory={profile_dir}')
#     return webdriver.Chrome(options=opts)

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

def create_driver(headless=False, user_data_dir=None, profile_dir=None, chrome_binary=None):
    opts = webdriver.ChromeOptions()
    opts.add_argument('--start-maximized')
    if headless:
        opts.add_argument('--headless=new')
    if user_data_dir:
        opts.add_argument(f'--user-data-dir={user_data_dir}')
    if profile_dir:
        opts.add_argument(f'--profile-directory={profile_dir}')
    if chrome_binary:
        opts.binary_location = chrome_binary  # å¯é€‰ï¼šæ˜¾å¼æŒ‡å®š Chrome å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„
    service = Service(ChromeDriverManager().install())  # è‡ªåŠ¨ä¸‹è½½å¹¶ä½¿ç”¨åŒ¹é…çš„ chromedriver
    return webdriver.Chrome(service=service, options=opts)


def find_and_collect_by_target_value(json_obj, target_value=None):
    """
    æŒ‰è®¢å•å·ç­›é€‰å¹¶åœ¨æ‰¾åˆ°æ—¶æŠŠ app_name å†™å…¥å…¨å±€å˜é‡ app_nameï¼Œç»§ç»­è¿”å›ç»“æœåˆ—è¡¨ã€‚
    """
    # é¡¶å±‚å‡½æ•°æœ¬èº«ä¸ç›´æ¥è¯»å†™ app_nameï¼Œåªåœ¨å†…éƒ¨åµŒå¥—å‡½æ•°é‡Œæ“ä½œ

    if not target_value:
        print("âŒ éœ€è¦æä¾› target_value (è®¢å•ç¼–å·)ï¼Œä¾‹å¦‚ 'IGT1185'")
        return []

    results = []
    target_str = str(target_value).strip().lower()

    def _search(obj):
        # è¿™é‡Œæ˜¾å¼å£°æ˜ä½¿ç”¨å…¨å±€ app_nameï¼Œé¿å… UnboundLocalError
        global app_name

        if isinstance(obj, dict):
            fld_order = obj.get("fldxQWjXD7")
            if isinstance(fld_order, dict):
                val = fld_order.get("value")
                if isinstance(val, list):
                    for entry in val:
                        if isinstance(entry, dict):
                            text = (entry.get("text") or "").strip()
                            if text.lower() == target_str:
                                # æå– app_nameï¼ˆæ¥è‡ª fldaShB3Gb çš„ç¬¬ä¸€ä¸ª value çš„ textï¼‰
                                found_app_name = None
                                flda = obj.get("fldaShB3Gb")
                                if isinstance(flda, dict):
                                    fval = flda.get("value")
                                    if isinstance(fval, list) and fval:
                                        first = fval[0]
                                        if isinstance(first, dict):
                                            found_app_name = (first.get("text") or "").strip() or None

                                # å°è¯•åœ¨ fldnLglcRi ä¸­å†™å…¥ app_name å¹¶è¿”å›å…¶ç¬¬ä¸€ä¸ª value
                                fldn = obj.get("fldnLglcRi")
                                if isinstance(fldn, dict):
                                    v = fldn.get("value")
                                    if isinstance(v, list) and v:
                                        first_item = v[0]
                                        if isinstance(first_item, dict):
                                            if found_app_name:
                                                first_item["app_name"] = found_app_name
                                            results.append(first_item)
                                        else:
                                            new_item = {"value": first_item}
                                            if found_app_name:
                                                new_item["app_name"] = found_app_name
                                            results.append(new_item)
                                    else:
                                        new_item = {}
                                        if found_app_name:
                                            new_item["app_name"] = found_app_name
                                        results.append(new_item)
                                else:
                                    if found_app_name:
                                        results.append({"app_name": found_app_name})
                                    else:
                                        results.append(obj)

                                # æ— è®ºä¹‹å‰æ˜¯å¦æœ‰å€¼ï¼Œç›´æ¥æŠŠæ‰¾åˆ°çš„ app_name èµ‹ç»™å…¨å±€å˜é‡
                                if found_app_name:
                                    app_name = found_app_name
                                    print(f"ğŸ”§ å·²è®¾ç½®å…¨å±€ app_name = `{app_name}`")

                                break

            # ç»§ç»­é€’å½’æŸ¥æ‰¾å­èŠ‚ç‚¹
            for v in obj.values():
                _search(v)

        elif isinstance(obj, list):
            for item in obj:
                _search(item)

    _search(json_obj)
    return results


def extract_vps_array_from_doc22(doc_data, cookies_str):
    global company_name, email
    print("ğŸ” æå–é¡µé¢ä¸­é¦–ä¸ªæœ‰æ•ˆçš„ @gmail.com é‚®ç®±...")
    results = []
    seen_urls = set()

    headers = {
        "Cookie": cookies_str or "",
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/123.0 Safari/537.36",
    }

    email_re = re.compile(r'(?<![A-Za-z0-9._%+\-])([A-Za-z0-9._%+\-]+@gmail\.com)\b', re.I)

    def _clean_gmail_emails(raw_text):
        found = email_re.findall(raw_text or "")
        unique = []
        seen = set()
        for e in found:
            ne = e.strip().lower()
            if ne and ne not in seen:
                seen.add(ne)
                unique.append(ne)
        final = []
        sset = set(unique)
        for e in unique:
            if len(e) > 1 and e[1:] in sset and len(e[0]) == 1:
                continue
            final.append(e)
        return final

    for item in doc_data:
        url = item.get("link")
        text = item.get("text", "")
        if not url and not text:
            continue
        if url in seen_urls:
            continue

        try:
            response = requests.get(url, headers=headers, timeout=15)
            if response.status_code != 200:
                print(f"âŒ è¯·æ±‚å¤±è´¥: {url}, çŠ¶æ€ç : {response.status_code}")
                continue

            page_content = html.unescape(response.text or "")
            emails = _clean_gmail_emails(page_content)
            primary = emails[0] if emails else ""

            # é¦–æ¬¡å‘ç°æ—¶ï¼Œè®¾ç½®å…¨å±€ company_name å’Œ emailï¼ˆå¦‚æœå°šæœªè®¾ç½®ï¼‰
            if not company_name:
                t = (text or "").strip()
                m = re.search(r'-(.+)$', t)
                if m:
                    company_name = m.group(1).strip()
                else:
                    parts = t.split(None, 1)
                    company_name = parts[1].strip() if len(parts) > 1 else (t or "")

            if primary and not email:
                email = primary.strip().lower()

            results.append(
                {
                    "text": text,
                    "url": url,
                    "email": primary,
                }
            )
            seen_urls.add(url)

        except Exception as e:
            print(f"âŒ è§£æå¤±è´¥: {url}, é”™è¯¯: {e}")

        # å¦‚æœå…¨å±€ä¿¡æ¯éƒ½å·²å¡«å……ï¼Œå¯ä»¥é€‰æ‹©æå‰é€€å‡ºä»¥åŠ å¿«é€Ÿåº¦
        if company_name and email:
            break

    # æŒ‰ text ä¸­çš„æ•°å­—æ’åºï¼ˆä¿æŒåŸæœ‰è¡Œä¸ºï¼‰
    def _extract_number(t):
        m = re.search(r"(\d+)", (t or ""))
        return int(m.group(1)) if m else 0

    results.sort(key=lambda x: _extract_number(x.get("text")))

    for item in results:
        print(f"{item.get('text')}")
        if item.get('email'):
            print(f"  é‚®ç®±: {item.get('email')}")
        else:
            print("  é‚®ç®±: æœªå‘ç° @gmail.com åœ°å€")
        print("-" * 50)

    print(f"âœ… æ€»æ•°é‡: {len(results)}")
    return results


def save_to_json(data, filename="none.json"):
    Path(filename).write_text(json.dumps(data, ensure_ascii=False, indent=2))
    # print(f"âœ… å·²ä¿å­˜ {len(data)} æ¡ç»“æœåˆ° {filename}")


import argparse

def ensure_github_ssh_keychain_ready(key_path: str = "~/.ssh/id_ed25519_common_hosts") -> None:
    """One-time friendly helper: load SSH key into macOS Keychain/ssh-agent.

    Goal: after you enter passphrase once, future runs never ask again.
    """
    try:
        kp = str(Path(key_path).expanduser())
        if not Path(kp).exists():
            return

        # If already loaded, nothing to do
        p = subprocess.run(["ssh-add", "-l"], text=True, capture_output=True)
        if p.returncode == 0 and (Path(kp).name in (p.stdout or "")):
            return

        # Use Keychain integration (macOS only)
        p = subprocess.run(["ssh-add", "--apple-use-keychain", kp], text=True)
        if p.returncode != 0:
            print(
                "âš ï¸ SSH key é¢„åŠ è½½å¤±è´¥ã€‚ä½ å¯ä»¥æ‰‹åŠ¨æ‰§è¡Œä¸€æ¬¡ï¼š\n"
                f"  ssh-add --apple-use-keychain {kp}\n"
                "è¾“å…¥ passphrase åï¼Œä»¥åå°±ä¸ä¼šå†æç¤ºã€‚"
            )
    except Exception:
        # Don't block main flow
        pass


if __name__ == "__main__":
    # åœ¨çœŸæ­£è¿è¡Œ git push ä¹‹å‰å…ˆå°è¯•é¢„åŠ è½½ä¸€æ¬¡
    ensure_github_ssh_keychain_ready()

    parser = argparse.ArgumentParser()
    parser.add_argument('id', nargs='?', help='è¡¨æ ¼ä¸­æŸ¥æ‰¾çš„ç¼–å·ï¼Œä¾‹å¦‚ IGT1128')
    args = parser.parse_args()

    # äº¤äº’è·å– idï¼ˆè‹¥æœªé€šè¿‡å‘½ä»¤è¡Œæä¾›ï¼‰
    if not args.id:
        try:
            args.id = input("è¯·è¾“å…¥ç¼–å·ï¼ˆä¾‹å¦‚ IGT1128ï¼‰ï¼š").strip()
        except (EOFError, KeyboardInterrupt):
            args.id = None

    if not args.id:
        print("âŒ æœªæä¾›ç¼–å·ï¼Œè„šæœ¬å°†é€€å‡ºã€‚\nç¤ºä¾‹ç”¨æ³•ï¼špython privacys.py IGT1128 --scan")
        sys.exit(2)

    try:
        records, cookies_str = get_gzip_json_from_api()
        if not records:
            print("âŒ æœªèƒ½è·å– recordsï¼Œè„šæœ¬é€€å‡º")
            sys.exit(1)

        available_records = find_and_collect_by_target_value(records, target_value=args.id)
        vps_result = extract_vps_array_from_doc22(available_records, cookies_str)

        driver = create_driver()
        run_privacy_flow(driver=driver, target_os="Android", publish_id=args.id)
    finally:
        if driver is not None:
            try:
                driver.quit()
            except Exception:
                pass
